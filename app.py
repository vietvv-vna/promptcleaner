import io
import re
import unicodedata
from typing import List

import streamlit as st
from docx import Document

st.set_page_config(page_title="DOCX ‚Üí Prompts TXT", page_icon="üìù", layout="wide")

# ---------- Heuristics ----------
DEFAULT_KEYWORDS = [
    "objective", "environment", "characters", "props", "dialogue",
    "teamwork", "camera", "lighting", "vfx", "audio", "rhythm",
    "transition", "cta"
]

def ascii_ratio(s: str) -> float:
    if not s:
        return 0.0
    return sum(1 for ch in s if ord(ch) < 128) / len(s)

def normalize_ws(s: str) -> str:
    # Gh√©p c√°c run trong Word, lo·∫°i b·ªè xu·ªëng d√≤ng th·ª´a
    s = " ".join(s.split())
    return s.strip()

def looks_like_prompt(
    text: str,
    min_len: int,
    min_ascii_ratio: float,
    min_keyword_hits: int,
    user_keywords: List[str]
) -> bool:
    if len(text) < min_len:
        return False

    # T·ª∑ l·ªá ASCII (nhi·ªÅu prompt ti·∫øng Anh d√†i)
    if ascii_ratio(text) < min_ascii_ratio:
        return False

    # ƒê·∫øm keyword
    keys = [k.strip().lower() for k in user_keywords if k.strip()]
    hits = sum(1 for k in keys if k in text.lower())
    if hits < min_keyword_hits:
        return False

    # Prompt th∆∞·ªùng l√† 1 block d√†i, √≠t d·∫•u c√¢u t∆∞∆°ng ·ª©ng s·ªë c√¢u h·∫°n ch·∫ø
    # (nh∆∞ng v·∫´n linh ho·∫°t ƒë·ªÉ kh√¥ng b·ªè s√≥t)
    # C√≥ th·ªÉ t√πy bi·∫øn n·∫øu c·∫ßn:
    return True

def extract_paragraphs_from_docx(file_bytes: bytes) -> List[str]:
    doc = Document(io.BytesIO(file_bytes))
    paras = []
    for p in doc.paragraphs:
        t = normalize_ws(p.text or "")
        if t:
            paras.append(t)
    return paras

def filter_prompts(
    paragraphs: List[str],
    min_len: int,
    min_ascii_ratio: float,
    min_keyword_hits: int,
    user_keywords: List[str]
) -> List[str]:
    prompts = [
        p for p in paragraphs
        if looks_like_prompt(p, min_len, min_ascii_ratio, min_keyword_hits, user_keywords)
    ]
    # Fallback nh·∫π n·∫øu kh√¥ng b·∫Øt ƒë∆∞·ª£c g√¨
    if len(prompts) == 0:
        prompts = [
            p for p in paragraphs
            if len(p) >= max(600, min_len) and ascii_ratio(p) >= max(0.7, min_ascii_ratio - 0.1)
        ]
    return prompts

# ---------- UI ----------
st.title("üìù DOCX ‚Üí Prompts TXT")
st.caption("T·∫£i file Word (.docx) c√≥ k·ªãch b·∫£n/prompt, app s·∫Ω l·ªçc v√† xu·∫•t TXT ch·ªâ ch·ª©a c√°c prompt.")

with st.sidebar:
    st.header("B·ªô l·ªçc (t√πy ch·ªânh)")
    min_len = st.slider("ƒê·ªô d√†i t·ªëi thi·ªÉu c·ªßa 1 prompt (k√Ω t·ª±)", 100, 3000, 500, 50)
    min_ascii = st.slider("T·ª∑ l·ªá ASCII t·ªëi thi·ªÉu", 0.0, 1.0, 0.75, 0.01)
    min_hits = st.slider("S·ªë l∆∞·ª£ng keyword t·ªëi thi·ªÉu kh·ªõp", 0, 10, 2, 1)
    kw_input = st.text_area(
        "Keywords (ph√¢n t√°ch b·∫±ng d·∫•u ph·∫©y)",
        value=", ".join(DEFAULT_KEYWORDS),
        height=100
    )
    user_keywords = [k.strip() for k in kw_input.split(",") if k.strip()]
    st.markdown("---")
    st.caption("G·ª£i √Ω: N·∫øu prompt c·ªßa b·∫°n lu√¥n c√≥ c√°c l·ªõp nh∆∞ 'objective, environment, camera, lighting, VFX, transition, CTA‚Ä¶', h√£y gi·ªØ t·ª´ kh√≥a n√†y ƒë·ªÉ l·ªçc ch√≠nh x√°c.")

uploaded = st.file_uploader("Ch·ªçn file .docx", type=["docx"])

if uploaded is not None:
    try:
        paragraphs = extract_paragraphs_from_docx(uploaded.read())
        st.success(f"ƒê√£ ƒë·ªçc {len(paragraphs)} ƒëo·∫°n vƒÉn t·ª´ t√†i li·ªáu.")
        prompts = filter_prompts(paragraphs, min_len, min_ascii, min_hits, user_keywords)

        st.subheader(f"K·∫øt qu·∫£: {len(prompts)} prompt")
        if len(prompts) == 0:
            st.warning("Kh√¥ng ph√°t hi·ªán prompt theo ti√™u ch√≠ hi·ªán t·∫°i. Vui l√≤ng n·ªõi ti√™u ch√≠ l·ªçc trong sidebar.")
        else:
            # Xem nhanh 3 prompt ƒë·∫ßu
            with st.expander("Xem nhanh (t·ªëi ƒëa 3 prompt ƒë·∫ßu)"):
                for i, pr in enumerate(prompts[:3], 1):
                    st.markdown(f"**Prompt #{i}**")
                    st.write(pr)

            # Xu·∫•t TXT
            sep = "\n\n"
            txt_content = sep.join(p.strip() for p in prompts)
            file_name_stem = uploaded.name.rsplit(".", 1)[0]
            out_name = f"{file_name_stem}_prompts_only.txt"
            st.download_button(
                label="‚¨áÔ∏è T·∫£i TXT ch·ª©a prompts",
                data=txt_content.encode("utf-8"),
                file_name=out_name,
                mime="text/plain"
            )

            # Tu·ª≥ ch·ªçn d·ªçn nhi·ªÖu (optional)
            st.markdown("---")
            st.subheader("T√πy ch·ªçn l√†m s·∫°ch th√™m (Optional)")
            rm_numbers = st.checkbox("Lo·∫°i b·ªè s·ªë heading/prefix d·∫°ng 'Scene 01:', 'Video 12 ‚Äì ' ·ªü ƒë·∫ßu d√≤ng")
            rm_quotes = st.checkbox("Lo·∫°i b·ªè ngo·∫∑c k√©p ƒë·∫ßu/cu·ªëi to√†n prompt")
            if st.button("√Åp d·ª•ng l√†m s·∫°ch & t·∫°o l·∫°i TXT"):
                cleaned = []
                for pr in prompts:
                    s = pr
                    if rm_numbers:
                        s = re.sub(r"^\s*(scene|video)\s*[:\-#]?\s*\d+\s*[\-\‚Äì:]\s*", "", s, flags=re.I)
                    if rm_quotes:
                        s = s.strip()
                        s = re.sub(r'^["‚Äú‚Äù]+', '', s)
                        s = re.sub(r'["‚Äú‚Äù]+$', '', s)
                    cleaned.append(s.strip())
                txt_content2 = "\n\n".join(cleaned)
                st.download_button(
                    label="‚¨áÔ∏è T·∫£i TXT ƒë√£ l√†m s·∫°ch",
                    data=txt_content2.encode("utf-8"),
                    file_name=f"{file_name_stem}_prompts_only_clean.txt",
                    mime="text/plain",
                    key="clean_download"
                )

    except Exception as e:
        st.error(f"L·ªói x·ª≠ l√Ω: {e}")
else:
    st.info("H√£y t·∫£i l√™n m·ªôt file .docx ƒë·ªÉ b·∫Øt ƒë·∫ßu.")
